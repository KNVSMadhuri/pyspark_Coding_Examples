#Reading multiple Parquet files from a folder and creating Dataframe.
df = sqlContext.read.parquet('/home/affine/Desktop/Train1/*.parquet')

# 1.How many hotel cluster are available in data
df1 = df.select('hotel_cluster').distinct().collect()
df1

#To Print Schema.
df.printSchema()

#2. How many search destination types are available in  srch_destination_type_id column
df.groupby('srch_destination_type_id').count().collect()

# 3. Percentage conversion for each hotel cluster using pyspark SQL
df.registerTempTable("df")
Percentage_conversion = sqlContext.sql("""
  SELECT hotel_cluster, COUNT(*) total, SUM(is_booking) total_is_booking, 
         CAST(AVG(is_booking) * 100 AS INT) percentage
  FROM df
  GROUP BY hotel_cluster""")
Percentage_conversion.show()

#4. Percentage conversion for each hotel cluster using pyspark Dataframe.
from pyspark.sql.functions import mean,count,sum
df.groupby(['hotel_cluster']).agg(count('*').alias('no. of search queries converted')
                                  ,sum('is_booking').alias('Total search queries')
                                  ,(mean('is_booking') * 100).cast('integer').alias('percentage')) .show()
                                  
#5. Calculating top 5 elements based on is_booking.
from pyspark.sql.functions import sum
distribution_aggregation = df.groupby(['hotel_cluster']).agg(sum('is_booking').alias('is_booking'),
                                  sum('srch_adults_cnt').alias('srch_adults_cnt'),
                                 sum('srch_children_cnt').alias('srch_children_cnt'),
                                 sum('srch_rm_cnt').alias('srch_rm_cnt'),
                                 sum('orig_destination_distance').alias('orig_destination_distance'),
                                 sum('site_name').alias('site_name'),
                                 sum('hotel_market').alias('hotel_market'),
                                 sum('srch_destination_type_id').alias('srch_destination_type_id'),
                                 sum('hotel_country').alias('hotel_country'))

                                 
distribution_aggregation.sort('is_booking', ascending=False).show(5)                                 
                                  
#5. Plotting graphs using pyspark

%pylab inline
subPercent = Percentage.toPandas() 
subPercent[:20].plot(x='hotel_cluster', y='percentage', kind='barh', alpha=0.5)  

#Find the top 5 hotel cluster having maximum booking
Percentage.sort('no_of_search_queries_converted', ascending=False).show(5)

#5. Calculating top 5 elements based on is_booking.
from pyspark.sql.functions import sum
df.filter('hotel_cluster = 91').groupby(['srch_adults_cnt']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['srch_children_cnt']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['srch_rm_cnt']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['orig_destination_distance']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['site_name']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['hotel_market']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['srch_destination_type_id']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['hotel_continent']).agg(sum('is_booking')).show()
df.filter('hotel_cluster = 91').groupby(['hotel_country']).agg(sum('is_booking')).show()
