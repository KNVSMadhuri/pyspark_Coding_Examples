#Reading multiple Parquet files from a folder and creating Dataframe.
df = sqlContext.read.parquet('/home/affine/Desktop/Train1/*.parquet')

# 1.How many hotel cluster are available in data
df1 = df.select('hotel_cluster').distinct().collect()
df1

#To Print Schema.
df.printSchema()

#2. How many search destination types are available in  srch_destination_type_id column
df.groupby('srch_destination_type_id').count().collect()

# 3. Percentage conversion for each hotel cluster using pyspark SQL
df.registerTempTable("df")
Percentage_conversion = sqlContext.sql("""
  SELECT hotel_cluster, COUNT(*) total, SUM(is_booking) total_is_booking, 
         CAST(AVG(is_booking) * 100 AS INT) percentage
  FROM df
  GROUP BY hotel_cluster""")
Percentage_conversion.show()

#4. Percentage conversion for each hotel cluster using pyspark Dataframe.
from pyspark.sql.functions import mean,count,sum
df.groupby(['hotel_cluster']).agg(count('*').alias('no. of search queries converted')
                                  ,sum('is_booking').alias('Total search queries')
                                  ,(mean('is_booking') * 100).cast('integer').alias('percentage')) .show()
